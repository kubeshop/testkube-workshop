name: Testkube on vCluster with ArgoCD
on:
  workflow_dispatch:
  pull_request:
    branches:
      - main

env:
  PR_NUMBER: ${{ github.event.number || github.run_id }}

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      - uses: depot/setup-action@v1

      - name: Login to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Create Docker tags and metadata for Backend
        id: backend-meta
        uses: docker/metadata-action@v5
        with:
          bake-target: 'backend-metadata'
          images: |
            caiomede/hotel-backend
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha

      - name: Build Backend image
        uses: depot/bake-action@v1.12.1
        with:
          project: ${{ secrets.DEPOT_PROJECT_ID }}
          files: |
            ./app/docker-bake.hcl
            cwd://${{ steps.backend-meta.outputs.bake-file }}
          push: true
          save: true
          save-tag: ${{ github.event.number || github.run_id }}

  run-test:
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GCP_CREDENTIALS }}'

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Install gke-gcloud-auth-plugin
        run: |
          gcloud components install gke-gcloud-auth-plugin

      - name: Get GKE credentials
        run: |
          gcloud container clusters get-credentials ${{ secrets.GKE_CLUSTER_NAME }} \
            --zone ${{ secrets.GKE_ZONE }} \
            --project ${{ secrets.GCP_PROJECT_ID }}

      - name: Install CLI tools
        run: |
          # Install vCluster CLI
          curl -sSL https://github.com/loft-sh/vcluster/releases/latest/download/vcluster-linux-amd64 -o vcluster
          chmod +x vcluster
          sudo mv vcluster /usr/local/bin

          # Install ArgoCD CLI
          curl -sSL -o argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
          chmod +x argocd-linux-amd64
          sudo mv argocd-linux-amd64 /usr/local/bin/argocd

      - name: Verify existing installations
        run: |
          echo "=== Host Cluster Info ==="
          kubectl cluster-info
          kubectl get nodes

          echo "=== Available Namespaces ==="
          kubectl get namespaces

          echo "=== Checking ArgoCD ==="
          kubectl get pods -n argocd || echo "ArgoCD namespace not found"

          echo "=== Checking Testkube ==="
          kubectl get pods -n testkube || echo "Testkube namespace not found"

      - name: Pre-flight Cleanup
        id: preflight-cleanup
        run: |
          echo "=== Pre-flight Cleanup for Ephemeral Demo ==="

          # Clean up any potential leftovers from previous demo runs
          echo "Cleaning up any leftover demo resources..."

          # Delete any existing demo namespaces
          kubectl get namespaces | grep "demo-" | awk '{print $1}' | xargs -r kubectl delete namespace --ignore-not-found=true || true

          # Delete any leftover ArgoCD applications
          kubectl get applications -n argocd 2>/dev/null | grep "nginx-vcluster-pr-" | awk '{print $1}' | xargs -r kubectl delete application -n argocd --ignore-not-found=true || true

          # Clean up any leftover vClusters
          vcluster list | grep "testkube-vcluster-" | awk '{print $1, $2}' | while read name namespace; do
            echo "Cleaning up leftover vCluster: $name in $namespace"
            vcluster delete "$name" --namespace "$namespace" || true
          done

          echo "=== Pre-flight cleanup completed - Ready for ephemeral demo ==="

      - name: Install or Verify ArgoCD
        id: install-argocd
        run: |
          echo "=== Checking ArgoCD Installation ==="

          # Check if ArgoCD namespace exists and has running pods
          if kubectl get namespace argocd >/dev/null 2>&1; then
            echo "ArgoCD namespace exists, checking pods..."
            ARGOCD_PODS=$(kubectl get pods -n argocd --no-headers 2>/dev/null | wc -l)
            if [ "$ARGOCD_PODS" -gt 0 ]; then
              echo "ArgoCD pods found, checking if they're ready..."
              kubectl get pods -n argocd
              # Wait for existing ArgoCD to be ready
              kubectl wait --for=condition=available --timeout=300s deployment/argocd-server -n argocd || echo "ArgoCD server not ready yet"
            else
              echo "ArgoCD namespace exists but no pods found, installing..."
              kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
              kubectl wait --for=condition=available --timeout=600s deployment/argocd-server -n argocd
            fi
          else
            echo "ArgoCD not found, installing..."
            kubectl create namespace argocd
            kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
            kubectl wait --for=condition=available --timeout=600s deployment/argocd-server -n argocd
          fi

          echo "=== ArgoCD Status ==="
          kubectl get pods -n argocd
          kubectl get svc -n argocd

      # ==================== vCluster Module ====================
      - name: Create vCluster
        id: create-vcluster
        run: |
          echo "=== Creating vCluster for PR $PR_NUMBER ==="

          # Create namespace
          kubectl create namespace demo-$PR_NUMBER --dry-run=client -o yaml | kubectl apply -f -

          # Create vCluster with proper configuration for ArgoCD access
          vcluster create testkube-vcluster-$PR_NUMBER \
            --namespace demo-$PR_NUMBER \
            --connect=false \
            --expose

          # Wait for vCluster to be ready
          echo "Waiting for vCluster to be ready..."
          sleep 30
          # kubectl wait --for=condition=ready pod -l app=vcluster --timeout=300s -n demo-$PR_NUMBER

          echo "=== vCluster created successfully ==="
          kubectl get all -n demo-$PR_NUMBER

          # Get vCluster service details for ArgoCD connection
          echo "=== vCluster Service Details ==="
          kubectl get svc -n demo-$PR_NUMBER

      - name: Setup vCluster connectivity and ArgoCD access
        id: setup-vcluster
        run: |
          echo "=== Setting up vCluster connectivity for ArgoCD ==="

          # Save the current (host) context
          HOST_CONTEXT=$(kubectl config current-context)
          echo "HOST_CONTEXT=$HOST_CONTEXT" >> $GITHUB_ENV
          echo "Host cluster context: $HOST_CONTEXT"

          # Connect to vCluster to set it up
          echo "=== Connecting to vCluster ==="
          vcluster connect testkube-vcluster-$PR_NUMBER --namespace demo-$PR_NUMBER &
          VCLUSTER_PID=$!
          echo "VCLUSTER_PID=$VCLUSTER_PID" >> $GITHUB_ENV

          # Wait for connection to establish
          sleep 30

          echo "=== Creating my-app namespace in vCluster ==="
          kubectl create namespace my-app --dry-run=client -o yaml | kubectl apply -f -

          echo "=== Verifying vCluster connection ==="
          kubectl get nodes
          kubectl get namespaces

          # IMPORTANT: Get the vCluster context name WHILE we're still connected
          VCLUSTER_CONTEXT=$(kubectl config current-context)
          echo "vCluster context name: $VCLUSTER_CONTEXT"
          echo "VCLUSTER_CONTEXT=$VCLUSTER_CONTEXT" >> $GITHUB_ENV

          # Save vCluster kubeconfig while we're still connected to vCluster
          echo "=== Saving vCluster kubeconfig ==="
          kubectl config view --raw > /tmp/vcluster-config.yaml

          # Debug: Check what contexts are available in the saved kubeconfig
          echo "=== Debugging saved kubeconfig ==="
          echo "Available contexts:"
          kubectl config view --kubeconfig /tmp/vcluster-config.yaml -o jsonpath='{.contexts[*].name}'
          echo ""
          echo "Current context in saved kubeconfig:"
          kubectl config view --kubeconfig /tmp/vcluster-config.yaml -o jsonpath='{.current-context}'
          echo ""

          # NOW switch back to host context (after capturing vCluster context)
          kubectl config use-context $HOST_CONTEXT

          echo "✅ vCluster kubeconfig prepared for ArgoCD"
          echo "✅ vCluster context captured: $VCLUSTER_CONTEXT"

      - name: Configure ArgoCD to Deploy to vCluster
        id: setup-argocd-vcluster
        run: |
          echo "=== Configuring ArgoCD to Deploy to vCluster ==="

          # CRITICAL: Make sure we're on the host cluster for ArgoCD operations
          echo "Ensuring we're on host cluster context: $HOST_CONTEXT"
          kubectl config use-context $HOST_CONTEXT

          # Verify current context
          echo "Current context: $(kubectl config current-context)"

          # Verify ArgoCD is available
          echo "=== Verifying ArgoCD Installation ==="
          if ! kubectl get namespace argocd >/dev/null 2>&1; then
            echo "❌ ArgoCD namespace not found on host cluster"
            echo "Available namespaces:"
            kubectl get namespaces
            exit 1
          fi

          # Check ArgoCD pods and wait more reliably
          echo "ArgoCD pods status:"
          kubectl get pods -n argocd

          # Check if argocd-server deployment exists before waiting
          if kubectl get deployment argocd-server -n argocd >/dev/null 2>&1; then
            echo "Waiting for ArgoCD server deployment to be available..."
            kubectl wait --for=condition=available --timeout=300s deployment/argocd-server -n argocd
          else
            echo "ArgoCD server deployment not found, checking pods directly..."
            # Alternative: wait for pod to be ready
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=argocd-server --timeout=300s -n argocd
          fi

          # Get ArgoCD credentials
          echo "Getting ArgoCD password..."
          ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
          if [ -z "$ARGOCD_PASSWORD" ]; then
            echo "❌ Failed to get ArgoCD password"
            kubectl get secrets -n argocd | grep argocd-initial-admin-secret
            exit 1
          fi

          # Try to get external IP first
          ARGOCD_SERVER=$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")

          if [ -z "$ARGOCD_SERVER" ]; then
            echo "No external IP found, using LoadBalancer IP from service..."
            # Check if service has external IP
            kubectl get svc argocd-server -n argocd
            ARGOCD_SERVER=$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")

            if [ -n "$ARGOCD_SERVER" ]; then
              echo "Found LoadBalancer IP: $ARGOCD_SERVER"
            else
              echo "No external IP found, setting up port-forward..."
              # Kill any existing port-forwards
              pkill -f "kubectl port-forward.*argocd-server" || true
              sleep 5

              # Start new port-forward
              kubectl port-forward svc/argocd-server -n argocd 8080:443 &
              ARGOCD_PORT_FORWARD_PID=$!
              echo "ARGOCD_PORT_FORWARD_PID=$ARGOCD_PORT_FORWARD_PID" >> $GITHUB_ENV

              # Wait for port-forward to be ready
              sleep 20
              ARGOCD_SERVER="localhost:8080"
            fi
          fi

          echo "ARGOCD_SERVER=$ARGOCD_SERVER" >> $GITHUB_ENV
          echo "ARGOCD_PASSWORD=$ARGOCD_PASSWORD" >> $GITHUB_ENV
          echo "Using ArgoCD server: $ARGOCD_SERVER"

          # Login to ArgoCD
          echo "=== Logging into ArgoCD ==="
          argocd login "$ARGOCD_SERVER" --username admin --password "$ARGOCD_PASSWORD" --insecure

          # Debug: Show what we're working with
          echo "Using vCluster context: $VCLUSTER_CONTEXT"
          echo "Available contexts in kubeconfig:"
          kubectl config view --kubeconfig /tmp/vcluster-config.yaml -o jsonpath='{.contexts[*].name}'
          echo ""

          # Add vCluster using the context name we captured
          echo "=== Adding vCluster to ArgoCD using kubeconfig ==="
          argocd cluster add "$VCLUSTER_CONTEXT" \
            --kubeconfig /tmp/vcluster-config.yaml \
            --name "vcluster-pr-$PR_NUMBER" \
            --yes

          # Wait a moment for the cluster to be registered
          sleep 10

          # Debug: List all clusters to see what's available
          echo "=== Debugging ArgoCD clusters ==="
          argocd cluster list
          echo ""

          # Get the cluster server URL - try multiple approaches
          echo "=== Getting vCluster server URL ==="
          VCLUSTER_SERVER=""

          # Method 1: Try exact match with name
          VCLUSTER_SERVER=$(argocd cluster list -o name | grep "vcluster-pr-$PR_NUMBER" | head -1)

          if [ -z "$VCLUSTER_SERVER" ]; then
            echo "Method 1 failed, trying method 2..."
            # Method 2: Try getting the server URL directly
            VCLUSTER_SERVER=$(argocd cluster list -o server | grep -v "^https://kubernetes.default.svc$" | grep -v "^NAME$" | head -1)
          fi

          if [ -z "$VCLUSTER_SERVER" ]; then
            echo "❌ Failed to get vCluster server URL"
            echo "Available clusters:"
            argocd cluster list
            exit 1
          fi

          echo "Using vCluster server: $VCLUSTER_SERVER"
          echo "VCLUSTER_SERVER=$VCLUSTER_SERVER" >> $GITHUB_ENV

          # Create ArgoCD application
          echo "=== Creating ArgoCD application ==="
          argocd app create backend-vcluster-pr-$PR_NUMBER \
            --repo ${{ github.server_url }}/${{ github.repository }} \
            --path app/backend/helm \
            --helm-set persistence.enabled=false \
            --dest-server "$VCLUSTER_SERVER" \
            --dest-namespace my-app \
            --revision ${{ github.head_ref || github.ref_name }} \
            --sync-policy automated \
            --upsert

          # Sync the application
          argocd app sync backend-vcluster-pr-$PR_NUMBER \
            --force \
            --timeout 300

          echo "✅ ArgoCD to vCluster configuration completed"

      # ==================== Testkube Module ====================
      - name: Setup Testkube
        uses: kubeshop/setup-testkube@v1
        with:
          organization: ${{ secrets.TESTKUBE_ORG_ID }}
          environment: ${{ secrets.TESTKUBE_ENV_ID }}
          token: ${{ secrets.TESTKUBE_API_TOKEN }}

      - name: Provision ephemeral runner in vCluster
        run: |
          echo "=== Provisioning Testkube runner in vCluster ==="

          # Ensure we're connected to vCluster
          if ! kubectl get nodes >/dev/null 2>&1; then
            echo "Reconnecting to vCluster..."
            kill $VCLUSTER_PID 2>/dev/null || true
            vcluster connect testkube-vcluster-$PR_NUMBER --namespace demo-$PR_NUMBER &
            VCLUSTER_PID=$!
            echo "VCLUSTER_PID=$VCLUSTER_PID" >> $GITHUB_ENV
            sleep 30
          fi

          # Provision ephemeral runner in vCluster
          testkube install runner github-actions-runner-${{ github.run_id }} \
            --create \
            --env paris \
            --namespace testkube \
            --floating

          # Create Chainsaw service account and role binding in vCluster
          echo "=== Setting up Chainsaw service account in vCluster ==="
          kubectl create serviceaccount chainsaw-service-account -n testkube --dry-run=client -o yaml | kubectl apply -f -
          kubectl create clusterrolebinding chainsaw-service-account-binding --clusterrole=view --serviceaccount=testkube:chainsaw-service-account -n testkube --dry-run=client -o yaml | kubectl apply -f -

          echo "=== Creating my-app namespace in vCluster ==="
          kubectl create namespace my-app --dry-run=client -o yaml | kubectl apply -f -

          helm upgrade --namespace testkube testkube-github-actions-runner-${{ github.run_id }} kubeshop/testkube-runner --reuse-values \
            --set execution.additionalNamespaces.my-app.serviceAccount.autoCreate=true \
            --set execution.additionalNamespaces.my-app.serviceAccount.name=testkube-my-app --wait

          # Wait a bit for runner to register
          sleep 30

          echo "=== Verifying Testkube runner installation ==="
          kubectl get events -n testkube --sort-by=.metadata.creationTimestamp | tail -20

          echo "=== Fetching Testkube runner logs ==="
          kubectl logs -l app.kubernetes.io/name=testkube-runner -n testkube --tail=20

          # Check runner status
          echo "=== Checking runner status ==="
          testkube get agent

          # Extract runner name ONLY from current cluster section
          ACTUAL_RUNNER_NAME=$(testkube get agent | grep "•:testkube" | awk '{print $1}' | head -1)

          if [ -z "$ACTUAL_RUNNER_NAME" ]; then
            echo "Failed to find runner in current cluster, trying more specific search..."
            # Fallback: search in the "Recognized agents" section specifically
            ACTUAL_RUNNER_NAME=$(testkube get agent | grep -A 20 "Recognized agents in current cluster" | grep "github-action-runner" | awk '{print $1}' | head -1)
          fi

          echo "Extracted runner name: $ACTUAL_RUNNER_NAME"
          echo "ACTUAL_RUNNER_NAME=$ACTUAL_RUNNER_NAME" >> $GITHUB_ENV

          # Verify it's not empty
          if [ -z "$ACTUAL_RUNNER_NAME" ]; then
            echo "❌ Failed to get runner name"
            echo "Debug - Available runners:"
            testkube get agent
            exit 1
          fi

          # Wait for runner pod to be ready
          echo "Waiting for runner pod to be ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=testkube-runner --timeout=300s -n testkube

          echo "=== Testkube runner provisioned in vCluster ==="

      - name: Run Chainsaw Tests with Testkube in vCluster
        id: run-chainsaw-tests
        continue-on-error: true
        run: |

          echo "=== Running Chainsaw Tests in vCluster with Testkube ==="
          echo "=== Running test with target runner: $ACTUAL_RUNNER_NAME ==="

          # Run the test workflow to validate the Nginx deployment using chainsaw
          testkube run testworkflow chainsaw-test -f \
            --target name=$ACTUAL_RUNNER_NAME \
            --tag test-type=chainsaw \
            --tag pr=PR-${{ github.run_id }} \
            --tag argocd-deployment=backend-vcluster-pr-$PR_NUMBER \
            --tag demo=gitopscon-chainsaw
            --config branch="${GITHUB_HEAD_REF:-$GITHUB_REF_NAME}"
            --config namespace=my-app

      - name: Run Backend Suite Tests with Testkube in vCluster
        id: run-k6-tests
        continue-on-error: true
        run: |

          echo "=== Running Backend Suite Tests in vCluster with Testkube ==="
          echo "=== Running test with target runner: $ACTUAL_RUNNER_NAME ==="

           # Run the test workflow to load test the Nginx service
          testkube run testworkflow backend-suites -f \
            --target name=$ACTUAL_RUNNER_NAME \
            --tag test-type=unit \
            --tag pr=PR-${{ github.run_id }} \
            --tag argocd-deployment=backend-vcluster-pr-$PR_NUMBER \
            --tag demo=gitopscon-chainsaw
            --config branch="${GITHUB_HEAD_REF:-$GITHUB_REF_NAME}"
            --config baseUrl=http://backend-vcluster-pr-$PR_NUMBER.my-app.svc:3000

      # ==================== Cleanup Module ====================
      - name: Cleanup Testkube Runner
        if: always()
        run: |
          echo "=== Cleaning up Testkube runner ==="
          testkube delete runner github-actions-runner-${{ github.run_id }} --delete --uninstall || true
          echo "=== Testkube runner cleanup completed ==="

      - name: Cleanup ArgoCD Application
        if: always()
        run: |
          echo "=== Cleaning up ArgoCD Application ==="

          # Switch to host context for ArgoCD operations
          kubectl config use-context $HOST_CONTEXT || true

          # Login to ArgoCD
          argocd login "$ARGOCD_SERVER" --username admin --password "$ARGOCD_PASSWORD" --insecure || true

          # Delete ArgoCD application
          kubectl delete application backend-vcluster-pr-$PR_NUMBER -n argocd --ignore-not-found=true

          # Remove cluster from ArgoCD
          argocd cluster rm "vcluster-pr-$PR_NUMBER" --yes || true

          echo "=== ArgoCD cleanup completed ==="

      - name: Cleanup vCluster
        if: always()
        run: |
          echo "=== Cleaning up vCluster ==="

          # Kill port-forward processes
          kill $VCLUSTER_PID $ARGOCD_PORT_FORWARD_PID 2>/dev/null || true
          pkill -f "kubectl port-forward" || true
          pkill -f "vcluster connect" || true

          # Switch back to host context
          kubectl config use-context $HOST_CONTEXT || true

          # Disconnect vCluster
          vcluster disconnect || true

          # Delete vCluster and namespace
          vcluster delete testkube-vcluster-$PR_NUMBER --namespace demo-$PR_NUMBER || true
          kubectl delete namespace demo-$PR_NUMBER --ignore-not-found=true

          echo "=== vCluster cleanup completed ==="

      - name: Report Test Failures
        if: always() && (steps.run-chainsaw-tests.outcome == 'failure' || steps.run-k6-tests.outcome == 'failure')
        run: |
          echo "Tests failed!"
          exit 1
